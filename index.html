<!DOCTYPE html>
<!--
    Moon by GetTemplates.co
    URL: https://gettemplates.co
-->
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>NVDS</title>
    <meta name="description" content="Core HTML Project">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- <link rel="shortcut icon" href="./img/favicon.ico"> -->

    <!-- External CSS -->
    <link rel="stylesheet" href="vendor/bootstrap/bootstrap.min.css">
    <link rel="stylesheet" href="vendor/select2/select2.min.css">
    <link rel="stylesheet" href="vendor/owlcarousel/owl.carousel.min.css">
    <link rel="stylesheet" href="vendor/lightcase/lightcase.css">

    <!-- Fonts -->
    <link rel="stylesheet" href="css/mycss.css">
    <!-- <link href="https://fonts.googleapis.com/css?family=Lato:300,400|Work+Sans:300,400,700" rel="stylesheet"> -->

    <!-- CSS -->
    <link rel="stylesheet" href="css/style.min.css">
    <link rel="stylesheet" href="https://cdn.linearicons.com/free/1.0.0/icon-font.min.css">
    <!-- <link href="https://file.myfontastic.com/7vRKgqrN3iFEnLHuqYhYuL/icons.css" rel="stylesheet"> -->

    <!-- Modernizr JS for IE8 support of HTML5 elements and media queries -->
    <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.8.3/modernizr.js"></script> -->

    <!-- pjw fontawesome.com -->
    <!-- <script src="https://kit.fontawesome.com/4db0969a88.js" crossorigin="anonymous"></script> -->

</head>

<body data-spy="scroll" data-target="#navbar-nav-header" class="static-layout">
    <div class="boxed-page">
        <nav id="gtco-header-navbar" class="navbar navbar-expand-lg py-4">
    <div class="container">
        <!-- <a class="navbar-brand d-flex align-items-center" href="/">
            <span class="lnr lnr-moon"></span>
        </a> -->
        <div style="transform: translateY(5px);"><img src="img/llogo.png" alt="Brand" width="200"></div>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-nav-header" aria-controls="navbar-nav-header" aria-expanded="false" aria-label="Toggle navigation">
            <span class="lnr lnr-menu"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbar-nav-header">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item">
                    <a class="nav-link" href="#home">Home</a>
                </li>
                &nbsp;
                <li class="nav-item">
                    <a class="nav-link" href="https://github.com/RaymondWang987/NVDS" target="_blank">GitHub</a>
                </li>
                &nbsp;
                <li class="nav-item">
                    <a class="nav-link" href="https://arxiv.org/abs/2307.08695" target="_blank">Paper</a>
                </li>
                &nbsp;
                <li class="nav-item">
                    <!-- <a class="nav-link" href="https://github.com/RaymondWang987/NVDS/blob/main/PDF/arxiv_230718.pdf" target="_blank">Supp</a>  -->
                    <a class="nav-link" href="#video">Video</a>
                </li>
                &nbsp;
                <li class="nav-item">
                    <a class="nav-link" href="#dataset">Dataset</a>
                </li>
            </ul>
        </div>
    </div>
</nav>  


<section id="title" class="bg-grey" style="padding-top: 80px;">
  <div class="container text-center" style="padding-left: 20px; padding-right: 20px;">
    <!-- <div class="paper-title">BokehMe: When Neural Rendering Meets<br>Classical Rendering</div> -->
    <h2 style="margin-top: 10px;"><b>Neural Video Depth Stabilizer</b></h2>
    <br>
    <div class="paper-author">
        <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=p_RnaI8AAAAJ" target="_blank">Yiran Wang</a><sup>1</sup>,&nbsp;
        <a href="https://www.semanticscholar.org/author/Min-Shi/1516268415" target="_blank">Min Shi</a><sup>1</sup>,&nbsp;
        <a href="https://scholar.google.com/citations?hl=zh-CN&user=i-2ghuYAAAAJ" target="_blank">Jiaqi Li</a><sup>1</sup>,&nbsp;
        <a href="https://orcid.org/0000-0002-8804-191X" target="_blank">Zihao Huang</a><sup>1</sup>,&nbsp;
        <br><a href="http://english.aia.hust.edu.cn/info/1085/1528.htm" target="_blank">Zhiguo Cao</a><sup>1</sup>,&nbsp;
        <a href="https://jimmie33.github.io/" target="_blank">Jianming Zhang</a><sup>2</sup>,&nbsp;
        <a href="https://sites.google.com/site/kexian1991/" target="_blank">Ke Xian</a><sup>3&thinsp;*</sup>,&nbsp;
        <a href="https://guosheng.github.io/" target="_blank">Guosheng Lin</a><sup>3</sup>
    </div>
    <br>
    <div class="paper-institution">
        <sup>1</sup>Huazhong University of Science and Technology<br>
        <sup>2</sup>Adobe Research &nbsp;&nbsp;
        <sup>3</sup>Nanyang Technological University
    </div>
    <br>
    <div class="paper-conference">ICCV 2023 </div>
    <!-- <br> -->
    <div class="paper-teaser" style="padding-top: 15px;"><img src="img/fig1_0717_2.png" alt="Teaser Image"></div>
    <br>
    <br>
    <br>
  </div>
</section>


<section id="gtco-counter" class="overlay bg-fixed">
    <div class="container">
        <div class="section-content">
            <div class="row" style="min-height: 115px">
                <!-- Counter Item -->
                <div class="col-md-3 col-sm-6 counter-item">
                    <a class="paper-icon nav-link" href="https://github.com/RaymondWang987/NVDS" target="_blank">
                        <svg xmlns="http://www.w3.org/2000/svg" width="60" height="60" fill="white" class="bi bi-github" viewBox="0 0 16 16">
                            <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
                        </svg>
                    </a>
                    <h5 style="margin-top: 10px; height: 20px;">GitHub</h5>
                </div>
                <!-- End of Counter Item -->
                <!-- Counter Item -->
                <div class="col-md-3 col-sm-6 counter-item">
                    <a class="paper-icon nav-link" href="https://arxiv.org/abs/2307.08695" target="_blank">
                        <svg xmlns="http://www.w3.org/2000/svg" width="60" height="60" fill="white" class="bi bi-file-earmark-text" viewBox="0 0 16 16">
                            <path d="M5.5 7a.5.5 0 0 0 0 1h5a.5.5 0 0 0 0-1h-5zM5 9.5a.5.5 0 0 1 .5-.5h5a.5.5 0 0 1 0 1h-5a.5.5 0 0 1-.5-.5zm0 2a.5.5 0 0 1 .5-.5h2a.5.5 0 0 1 0 1h-2a.5.5 0 0 1-.5-.5z"/>
                            <path d="M9.5 0H4a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h8a2 2 0 0 0 2-2V4.5L9.5 0zm0 1v2A1.5 1.5 0 0 0 11 4.5h2V14a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1V2a1 1 0 0 1 1-1h5.5z"/>
                        </svg>
                    </a>
                    <h5 style="margin-top: 10px; height: 20px;">Paper</h5>
                </div>
                <!-- End of Counter Item -->
                <!-- Counter Item -->
                <div class="col-md-3 col-sm-6 counter-item">
                    <a class="paper-icon nav-link" href="https://github.com/RaymondWang987/NVDS/blob/main/PDF/SUPPV1.pdf" target="_blank">
                        <svg xmlns="http://www.w3.org/2000/svg" width="60" height="60" fill="white" class="bi bi-file-earmark-plus" viewBox="0 0 16 16">
                            <path d="M8 6.5a.5.5 0 0 1 .5.5v1.5H10a.5.5 0 0 1 0 1H8.5V11a.5.5 0 0 1-1 0V9.5H6a.5.5 0 0 1 0-1h1.5V7a.5.5 0 0 1 .5-.5z"/>
                            <path d="M14 4.5V14a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V2a2 2 0 0 1 2-2h5.5L14 4.5zm-3 0A1.5 1.5 0 0 1 9.5 3V1H4a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h8a1 1 0 0 0 1-1V4.5h-2z"/>
                        </svg>
                    </a>
                    <h5 style="margin-top: 10px; height: 20px;">Supplementary<br>Material</h5>
                </div>
                <!-- End of Counter Item -->
                <!-- Counter Item -->
                <div class="col-md-3 col-sm-6 counter-item">
                    <a class="paper-icon nav-link" href="#dataset">
                        <svg t="1648022423359" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2247" width="60" height="60" fill="white">
                            <path d="M512 0c-215.79776 0-448 65.06496-448 207.99488l0 608.01024c0 142.88896 232.20224 207.99488 448 207.99488 215.77728 0 448-65.1264 448-207.99488l0-608.01024c0-142.9504-232.26368-207.99488-448-207.99488zM896 816.00512c0 79.48288-171.9296 143.99488-384 143.99488-212.09088 0-384-64.512-384-143.99488l0-119.54176c66.10944 68.13696 225.60768 103.54688 384 103.54688s317.89056-35.4304 384-103.54688l0 119.54176zM896 624.00512l-0.12288 0c0 0.32768 0.12288 0.67584 0.12288 0.98304 0 79.01184-171.9296 143.01184-384 143.01184s-384-64-384-143.01184c0-0.32768 0.12288-0.67584 0.12288-0.98304l-0.12288 0 0-119.56224c66.10944 68.13696 225.60768 103.54688 384 103.54688s317.89056-35.4304 384-103.54688l0 119.56224zM896 432.00512l-0.12288 0c0 0.32768 0.12288 0.67584 0.12288 0.98304 0 79.01184-171.9296 143.01184-384 143.01184s-384-64-384-143.01184c0-0.32768 0.12288-0.67584 0.12288-0.98304l-0.12288 0 0-109.95712c83.8656 63.8976 237.60896 93.94176 384 93.94176s300.1344-30.04416 384-93.94176l0 109.95712zM512 352.01024c-212.09088 0-384-64.512-384-143.99488 0-79.54432 171.90912-143.99488 384-143.99488 212.0704 0 384 64.45056 384 143.99488 0 79.48288-171.9296 143.99488-384 143.99488zM768 832c0-17.67424 14.336-32.01024 32.01024-32.01024s32.01024 14.336 32.01024 32.01024c0 17.67424-14.336 32.01024-32.01024 32.01024s-32.01024-14.336-32.01024-32.01024zM768 640c0-17.67424 14.336-32.01024 32.01024-32.01024s32.01024 14.336 32.01024 32.01024c0 17.67424-14.336 32.01024-32.01024 32.01024s-32.01024-14.336-32.01024-32.01024zM768 448c0-17.67424 14.336-32.01024 32.01024-32.01024s32.01024 14.336 32.01024 32.01024c0 17.67424-14.336 32.01024-32.01024 32.01024s-32.01024-14.336-32.01024-32.01024z" p-id="2248"></path>
                        </svg>
                    </a>
                    <h5 style="margin-top: 10px; height: 20px;">Dataset<br>(Coming Soon)</h5>
                </div>
                <!-- End of Counter Item -->
            </div>
        </div>
    </div>
</section>
<!-- End of Counter Section --> 

<section id="abstract" class="bg-white">
    <div class="container" style="padding-left: 20px; padding-right: 20px;">
        <div class="section-content">
            <div class="title-warp">
                <h2 class="section-title">Abstract</h2>
            </div>
            <div class="paper-text">
                <p>
                    Video depth estimation aims to infer temporally consistent depth. Some methods achieve temporal consistency by finetuning a single-image depth model during test time using geometry and re-projection constraints, which is inefficient and not robust. An alternative approach is to learn how to enforce temporal consistency from data, but this requires well-designed models and sufficient video depth data. To address these challenges, we propose a plug-and-play framework called Neural Video Depth Stabilizer (NVDS) that stabilizes inconsistent depth estimations and can be applied to different single-image depth models without extra effort. We also introduce a large-scale dataset, Video Depth in the Wild (VDW), which consists of 14,203 videos with over two million frames, making it the largest natural-scene video depth dataset to our knowledge. We evaluate our method on the VDW dataset as well as two public benchmarks and demonstrate significant improvements in consistency, accuracy, and efficiency compared to previous approaches. Our work serves as a solid baseline and provides a data foundation for learning-based video depth models. We will release our dataset and code for future research.
                </p>
            </div>
        </div>
    </div>
</section>


<section id="video" class="bg-grey" href="#video">
    <div class="container" style="padding-left: 20px; padding-right: 20px;">
        <div class="section-content">
            <div class="title-warp">
                <h2 class="section-title">Video</h2>
            </div>
            <div class="body">
                <div style="position: relative; padding-top: 55%; text-align: center;">
                    <iframe style="position: absolute; top: 2.5%; left: 2.5%; width: 95%; height: 100%;" src="https://www.youtube.com/embed/SNV9F-60xrE" frameborder="0" allowfullscreen="allowfullscreen"></iframe>
                </div>
                <!-- <video width="100%" controls>
                    <source src="img/video.mp4"  type="video/mp4">
                </video> -->
            </div>
        </div>
    </div>
</section>






<section id="method" class="bg-white">
    <div class="container" style="padding-left: 20px; padding-right: 20px;">
        <div class="section-content">
            <div class="title-warp">
                <h2 class="section-title">Method&Experiments</h2>
            </div>

            <div class="tab_contents">
                <ul class="tab_nav">
                    <li class="tabNav_active">
                        <h5>NVDS <br> Framework</h5>
                    </li>
                    <li>
                        <h5>Visual <br> Comparisons</h5>
                    </li>
                    <li>
                        <h5>Quantitative <br> Results</h5>
                    </li>
                </ul>
                <ul class="tab_box">
                    <li class="tabBox_active">
                        <div>
                            <p>Overview of the neural video depth stabilizer. Our framework consists of a depth predictor and a stabilization network. The depth predictor can be any single-image depth model which produces initial flickering disparity maps. Then, the stabilization network refines the flickering disparity maps into temporally consistent ones. The stabilization network functions in a sliding window manner: the frame to be predicted fetches information from adjacent frames for stabilization. During inference, our NVDS framework can be directly adapted to any off-the-shelf depth predictors in a plug-and-play manner. We also devise bidirectional inference to further improve consistency.</p>
                            <!-- <div style="text-align: center;"><a href="img/framework.png" target="_blank"><img src="img/framework.png" alt="Framework" width="60%"></a></div> -->
                            <div style="text-align: center;"><img src="img/pipeline_0307.png" alt="Framework" width="100%"></div>
                        </div>
                    </li>
                    <li>
                        <div>
                            <p>Visual comparisons. DeepV2D and Robust-CVD  show obvious artifacts in those videos. We draw the scanline slice over time; fewer zigzagging pattern means better consistency. Compared with the other video depth methods, our NVDS is more robust on natural scenes and achieves better spatial accuracy and temporal consistency.</p>
                            <!-- <div style="text-align: center;"><a href="img/error_analysis.png" target="_blank"><img src="img/error_analysis.png" alt="Error Analysis" width="100%"></a></div> -->
                            <div style="text-align: center;"><img src="img/qiepian.png" alt="Error Analysis" width="100%"></div>
                        </div>
                    </li>
                    <li>
                        <div>
                            <p>Comparisons with the state-of-the-art approaches. We report the total time of processing eight 640 Ã— 480 frames by different methods on one NVIDIA RTX A6000 GPU. Best performance is in boldface. Second best is underlined.</p>
                            <!-- <div style="text-align: center;"><a href="img/neural_renderer.png" target="_blank"><img src="img/neural_renderer.png" alt="Neural Renderer" width="100%"></a></div> -->
                            <div style="text-align: center;"><img src="img/tab1.png" alt="Neural Renderer" width="100%"></div>
                        </div>
                    </li>
                </ul>
            </div>
        </div>
    </div>
</section>



<section id="dataset" class="bg-grey">
    <div class="container" style="padding-left: 20px; padding-right: 20px;">
        <div class="section-content">
            <div class="title-warp">
                <h2 class="section-title">Dataset</h2>
            </div>

            <div class="paper-text">
                <p>Current video depth datasets are limited in both diversity and volume. To compensate for the data shortage and boost the performance of learning-based video depth models, we elaborate a large-scale natural- scene dataset, Video Depth in the Wild (VDW). We collect stereo videos from four data sources: movies, animations, documentaries, and web videos. To our best knowledge, our VDW dataset is currently the largest video depth dataset with the most diverse video scenes. We will build the official website to release VDW dataset for the community. We will update the website and links when we are ready. Stay tuned!</p>.
            </div>
            <div style="text-align: center;"><img src="img/gt_supp1.png" alt="Error Analysis" width="100%"></div>
            <!-- <table width="95%" align="center">
                <tr>
                    <td><img src="img/BLB/data/277/image.jpg" alt="BLB image 1"></td>
                    <td><img src="img/BLB/data/278/image.jpg" alt="BLB image 2"></td>
                    <td><img src="img/BLB/data/279/image.jpg" alt="BLB image 3"></td>
                    <td><img src="img/BLB/data/280/image.jpg" alt="BLB image 4"></td>
                    <td><img src="img/BLB/data/281/image.jpg" alt="BLB image 5"></td>
                </tr>
                <tr>
                    <td><img src="img/BLB/data/283/image.jpg" alt="BLB image 6"></td>
                    <td><img src="img/BLB/data/290/image.jpg" alt="BLB image 7"></td>
                    <td><img src="img/BLB/data/291/image.jpg" alt="BLB image 8"></td>
                    <td><img src="img/BLB/data/292/image.jpg" alt="BLB image 9"></td>
                    <td><img src="img/BLB/data/293/image.jpg" alt="BLB image 10"></td>
                </tr>
            </table> -->

        </div>
    </div>
</section>


<section id="citation" class="bg-grey">
    <div class="container" style="padding-left: 20px; padding-right: 20px;">
        <div class="section-content">
            <div class="title-warp">
                <h2 class="section-title">Citation</h2>
            </div>

            <div class="paper-text">
                <textarea class="form-control placeholder" readonly="" style="height: 155px; resize: none;">@inproceedings{Wang2023NVDS,
  title = {Neural Video Depth Stabilizer},
  author = {Yiran, Wang and Min, Shi and Jiaqi, Li and Zihao, Huang and Zhiguo, Cao and Jianming, Zhang and Ke, Xian and Guosheng, Lin},
  booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year = {2023}
}</textarea>
            </div>
        </div>
    </div>
</section>


<footer class="mastfoot mb-3 bg-grey py-4 border-top">
    <div class="inner container" style="text-align: center;">
        <p class="mb-0">This work was supported by Adobe. This website template was inspired by <a href="https://www.free-css.com/free-css-templates/page273/moon" target="_blank">Moon</a>.</p>
    </div>
</footer>
    
</div>
    <!-- External JS -->
    <!-- <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1/jquery.js"></script> -->
    <script src="js/ajax.js"></script>
    <script src="vendor/bootstrap/popper.min.js"></script>
    <script src="vendor/bootstrap/bootstrap.min.js"></script>
    <script src="vendor/select2/select2.min.js "></script>
    <script src="vendor/owlcarousel/owl.carousel.min.js"></script>
    <script src="vendor/isotope/isotope.min.js"></script>
    <script src="vendor/lightcase/lightcase.js"></script>
    <script src="vendor/waypoints/waypoint.min.js"></script>
    <script src="vendor/countTo/jquery.countTo.js"></script>

    <!-- Main JS -->
    <script src="js/myjs.js "></script>
    <script src="js/app.min.js "></script>
    <!-- <script src="//localhost:35729/livereload.js"></script> -->
</body>
</html>
